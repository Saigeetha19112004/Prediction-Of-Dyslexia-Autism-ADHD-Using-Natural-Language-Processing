{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "76a54703",
        "outputId": "f66ffa00-553c-4c69-9919-629a01d967b8"
      },
      "source": [
        "!pip install reportlab"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: reportlab in /usr/local/lib/python3.12/dist-packages (4.4.4)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.12/dist-packages (from reportlab) (11.3.0)\n",
            "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.12/dist-packages (from reportlab) (3.4.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fuzz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mXtugHbYQsrn",
        "outputId": "988f57b2-cdad-400f-922f-d45b59a427bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: fuzz in /usr/local/lib/python3.12/dist-packages (0.1.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PHo_kKQKQzaR",
        "outputId": "b8dd6819-ca97-4451-b2aa-8db5dfa91616"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk) (8.3.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk) (1.5.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk) (4.67.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fuzzywuzzy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AUQ3bR1fRoTO",
        "outputId": "c210857c-f867-4fb7-ef30-11e27175d88a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: fuzzywuzzy in /usr/local/lib/python3.12/dist-packages (0.18.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import nltk\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "from reportlab.lib.pagesizes import letter\n",
        "from reportlab.pdfgen import canvas\n",
        "from fuzzywuzzy import fuzz\n",
        "from nltk.corpus import words as nltk_words\n",
        "from nltk.tokenize import word_tokenize\n"
      ],
      "metadata": {
        "id": "DdipzWoHR8uB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---- Constants ----\n",
        "SIMILARITY_THRESHOLD = 50\n",
        "DYSLEXIA_SCORE_THRESHOLD = 3.5\n",
        "\n",
        "# Simple mapping for questionnaire answers to numeric scores\n",
        "ANSWER_SCORE_MAP = {\n",
        "    \"never\": 0,\n",
        "    \"lessOften\": 1,\n",
        "    \"sometimes\": 2,\n",
        "    \"moreOften\": 3\n",
        "}\n",
        "\n",
        "# Ensure necessary NLTK resources are available\n",
        "def ensure_nltk_resources():\n",
        "    try:\n",
        "        nltk.data.find('tokenizers/punkt')\n",
        "    except LookupError:\n",
        "        nltk.download('punkt')\n",
        "    try:\n",
        "        nltk.data.find('corpora/words')\n",
        "    except LookupError:\n",
        "        nltk.download('words')\n",
        "\n",
        "ensure_nltk_resources()\n",
        "\n",
        "# Create a set of English words from NLTK\n",
        "english_vocab = set(w.lower() for w in nltk_words.words())\n",
        "\n",
        "# Dyslexic confusions (kept from your original)\n",
        "DYSLEXIC_LETTER_CONFUSIONS = [\n",
        "    ('b', 'd'), ('p', 'q'), ('m', 'w'), ('n', 'u'), ('n', 'r'),\n",
        "    ('i', 'j'), ('a', 'e'), ('s', 'z'), ('f', 't'), ('c', 'k'),\n",
        "    ('g', 'q'), ('h', 'n'), ('v', 'w'), ('b', 'p'), ('c', 's'),\n",
        "    ('d', 't'), ('o', 'e'), ('a', 'o'), ('u', 'v'), ('m', 'n')\n",
        "]\n",
        "\n",
        "DYSLEXIC_WORD_CONFUSIONS = [\n",
        "    ('was', 'saw'), ('there', 'their'), ('here', 'hear'),\n",
        "    ('you', 'your'), ('where', 'wear'), ('to', 'too', 'two'),\n",
        "    ('its', \"it's\"), ('right', 'write'), ('flower', 'flour'),\n",
        "    ('buy', 'by', 'bye'), ('no', 'know'), ('for', 'four'), ('sun', 'son'),\n",
        "    ('allowed', 'aloud'), ('hour', 'our'), ('blew', 'blue'), ('sew', 'sow'),\n",
        "    ('be', 'bee'), ('one', 'won')\n",
        "]\n"
      ],
      "metadata": {
        "id": "aSI40A1FnIPR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---- Text utilities ----\n",
        "def tokenize_and_clean_text(text):\n",
        "    words = word_tokenize(text.lower())\n",
        "    return [word for word in words if word.isalnum()]\n",
        "\n",
        "def is_exact_match(user_text, random_sentence):\n",
        "    return user_text.lower().strip() == random_sentence.lower().strip()\n",
        "\n",
        "def are_strings_similar(str1, str2, threshold):\n",
        "    return fuzz.ratio(str1.lower(), str2.lower()) >= threshold\n",
        "\n",
        "# ---- Dyslexia scoring (kept and slightly simplified) ----\n",
        "def calculate_word_dyslexia_score(word, random_sentence):\n",
        "    word_tokens = tokenize_and_clean_text(word)\n",
        "    sentence_tokens = tokenize_and_clean_text(random_sentence)\n",
        "    dyslexia_score = 0.0\n",
        "\n",
        "    # defensive checks\n",
        "    if not word_tokens or not sentence_tokens:\n",
        "        return 0.0\n",
        "\n",
        "    # if full match reduce score (encourage correct copying)\n",
        "    if \" \".join(word_tokens) == \" \".join(sentence_tokens):\n",
        "        return 0.0\n",
        "\n",
        "    for word_token in word_tokens:\n",
        "        token_dyslexia_score = 0.0\n",
        "\n",
        "        if word_token not in english_vocab:\n",
        "            token_dyslexia_score += 3.0\n",
        "\n",
        "        # letter-pair confusions (if both letters appear in token)\n",
        "        for confusion in DYSLEXIC_LETTER_CONFUSIONS:\n",
        "            if confusion[0] in word_token and confusion[1] in word_token:\n",
        "                token_dyslexia_score += 1.2  # smaller increment\n",
        "\n",
        "        # word-level confusion (if token contains confusion words)\n",
        "        for confusion in DYSLEXIC_WORD_CONFUSIONS:\n",
        "            # if token equals or contains any confusion forms\n",
        "            if any(conf_word == word_token for conf_word in confusion):\n",
        "                token_dyslexia_score += 2.0\n",
        "\n",
        "        # transposition check vs first token of sentence\n",
        "        ref = sentence_tokens[0]\n",
        "        if len(word_token) == len(ref):\n",
        "            transpositions = [(word_token[:i] + word_token[i + 1] + word_token[i] + word_token[i + 2:]) for i in range(len(word_token) - 1)]\n",
        "            if ref in transpositions:\n",
        "                token_dyslexia_score += 1.8\n",
        "\n",
        "        # reversed word\n",
        "        if word_token[::-1] == ref:\n",
        "            token_dyslexia_score += 1.8\n",
        "\n",
        "        dyslexia_score += token_dyslexia_score\n",
        "\n",
        "        if token_dyslexia_score == 0:\n",
        "            dyslexia_score -= 0.3\n",
        "\n",
        "    return max(dyslexia_score, 0.0)\n",
        "\n",
        "def dyslexia_analysis(user_text, random_sentence):\n",
        "    if is_exact_match(user_text, random_sentence):\n",
        "        return 0.0\n",
        "\n",
        "    words = tokenize_and_clean_text(user_text)\n",
        "    if not words:\n",
        "        return 0.0\n",
        "\n",
        "    dyslexia_scores = []\n",
        "    for word in words:\n",
        "        dyslexia_scores.append(calculate_word_dyslexia_score(word, random_sentence))\n",
        "\n",
        "    avg_score = round(sum(dyslexia_scores) / len(dyslexia_scores), 3)\n",
        "    return avg_score\n",
        "\n",
        "# ---- Questionnaire-based autism & ADHD scoring ----\n",
        "# We will ask a short list of behavioral questions (you can edit these)\n",
        "AUTISM_QUESTIONS = [\n",
        "    (\"respNamesBy9months\", \"Responds to name by 9 months? (never/lessOften/sometimes/moreOften): \"),\n",
        "    (\"noPlaywithOtherby36Months\", \"Plays with other children by 36 months? (never/lessOften/sometimes/moreOften): \"),\n",
        "    (\"noGestures12Months\", \"Used gestures by 12 months? (never/lessOften/sometimes/moreOften): \"),\n",
        "    (\"repeatWords\", \"Repeats words or phrases (echolalia)? (never/lessOften/sometimes/moreOften): \"),\n",
        "    (\"noAttention\", \"Has poor attention or focus? (never/lessOften/sometimes/moreOften): \"),\n",
        "    (\"unusualEating\", \"Shows unusual eating behaviors? (never/lessOften/sometimes/moreOften): \")\n",
        "]\n",
        "\n",
        "ADHD_QUESTIONS = [\n",
        "    (\"hyperactivity\", \"Shows hyperactive behavior? (never/lessOften/sometimes/moreOften): \"),\n",
        "    (\"forgetfulness\", \"Is forgetful in daily activities? (never/lessOften/sometimes/moreOften): \"),\n",
        "    (\"disobeyInst\", \"Often disobeys instructions? (never/lessOften/sometimes/moreOften): \"),\n",
        "    (\"repTempTantrum\", \"Frequent temper tantrums? (never/lessOften/sometimes/moreOften): \"),\n",
        "    (\"noAttention\", \"Difficulty sustaining attention? (never/lessOften/sometimes/moreOften): \"),\n",
        "    (\"harmingNature\", \"Shows impulsive harming behaviors? (never/lessOften/sometimes/moreOften): \")\n",
        "]\n",
        "\n",
        "def ask_question(prompt):\n",
        "    while True:\n",
        "        ans = input(prompt).strip()\n",
        "        if ans in ANSWER_SCORE_MAP:\n",
        "            return ans\n",
        "        print(\"Invalid answer. Use one of: never, lessOften, sometimes, moreOften\")\n",
        "\n",
        "def autism_analysis_from_answers(answers_dict):\n",
        "    # Score autism using weights: early-develop symptoms and social-communication get higher weight\n",
        "    score = 0.0\n",
        "    weights = {\n",
        "        \"respNamesBy9months\": 2.5,\n",
        "        \"noPlaywithOtherby36Months\": 2.5,\n",
        "        \"noGestures12Months\": 2.5,\n",
        "        \"repeatWords\": 1.8,\n",
        "        \"noAttention\": 1.0,\n",
        "        \"unusualEating\": 0.8\n",
        "    }\n",
        "    for key, weight in weights.items():\n",
        "        val = ANSWER_SCORE_MAP.get(answers_dict.get(key, \"never\"), 0)\n",
        "        score += val * weight\n",
        "\n",
        "    # Normalize roughly to a 0-? range and set threshold\n",
        "    # Higher score -> higher likelihood of autism\n",
        "    return round(score, 3)\n",
        "\n",
        "def adhd_analysis_from_answers(answers_dict):\n",
        "    # ADHD scoring focuses on hyperactivity/impulsivity and inattention\n",
        "    score = 0.0\n",
        "    weights = {\n",
        "        \"hyperactivity\": 2.2,\n",
        "        \"forgetfulness\": 1.6,\n",
        "        \"disobeyInst\": 1.0,\n",
        "        \"repTempTantrum\": 0.6,\n",
        "        \"noAttention\": 2.2,\n",
        "        \"harmingNature\": 0.8\n",
        "    }\n",
        "    for key, weight in weights.items():\n",
        "        val = ANSWER_SCORE_MAP.get(answers_dict.get(key, \"never\"), 0)\n",
        "        score += val * weight\n",
        "\n",
        "    return round(score, 3)\n",
        "\n",
        "# Heuristic thresholds (transparent & adjustable)\n",
        "AUTISM_THRESHOLD = 18.0   # above this -> \"high likelihood\"\n",
        "ADHD_THRESHOLD = 12.0     # above this -> \"high likelihood\""
      ],
      "metadata": {
        "id": "5kPgMfk5nElV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---- PDF report generator (combined) ----\n",
        "def generate_pdf_report(user_responses, dyslexia_scores, avg_score, dyslexia_verdict,\n",
        "                        autism_score, autism_verdict,\n",
        "                        adhd_score, adhd_verdict,\n",
        "                        dyscalculia_score, dyscalculia_verdict, # Added dyscalculia parameters\n",
        "                        user_name, user_id):\n",
        "    pdf_filename = f\"{user_name}_{user_id}_neurodev_report.pdf\"\n",
        "    c = canvas.Canvas(pdf_filename, pagesize=letter)\n",
        "    width, height = letter\n",
        "\n",
        "    # Title\n",
        "    c.setFont(\"Helvetica-Bold\", 16)\n",
        "    title_text = \"Neurodevelopmental Screening Report\"\n",
        "    title_x = (width - c.stringWidth(title_text, \"Helvetica-Bold\", 16)) / 2\n",
        "    c.drawString(title_x, height - 40, title_text)\n",
        "\n",
        "    y = height - 70\n",
        "    c.setFont(\"Helvetica-Bold\", 12)\n",
        "    c.drawString(100, y, \"Full Legal Name:\")\n",
        "    c.setFont(\"Helvetica\", 12)\n",
        "    c.drawString(220, y, user_name)\n",
        "\n",
        "    y -= 18\n",
        "    c.setFont(\"Helvetica-Bold\", 12)\n",
        "    c.drawString(100, y, \"State ID Number:\")\n",
        "    c.setFont(\"Helvetica\", 12)\n",
        "    c.drawString(220, y, user_id)\n",
        "\n",
        "    # Dyslexia section\n",
        "    y -= 28\n",
        "    c.setFont(\"Helvetica-Bold\", 13)\n",
        "    c.drawString(100, y, \"Dyslexia Test\")\n",
        "    y -= 16\n",
        "    c.setFont(\"Helvetica\", 12)\n",
        "    c.drawString(100, y, f\"Average Dyslexia Score: {avg_score:.3f}\")\n",
        "    y -= 14\n",
        "    c.drawString(100, y, f\"Verdict: {dyslexia_verdict}\")\n",
        "\n",
        "    # list responses & scores\n",
        "    y -= 22\n",
        "    c.setFont(\"Helvetica-Bold\", 13)\n",
        "    c.drawString(100, y, \"User Entered Sentences and Scores:\")\n",
        "    y -= 14\n",
        "    c.setFont(\"Helvetica\", 11)\n",
        "    if user_responses:\n",
        "        for i, (resp, score) in enumerate(zip(user_responses, dyslexia_scores), 1):\n",
        "            if y < 80:\n",
        "                c.showPage()\n",
        "                y = height - 40\n",
        "            c.drawString(110, y, f\"{resp[:80]}\")  # truncated display\n",
        "            y -= 12\n",
        "            c.drawString(130, y, f\"Score: {score:.3f}\")\n",
        "            y -= 14\n",
        "    else:\n",
        "        c.drawString(110, y, \"No sentences provided.\")\n",
        "        y -= 14\n",
        "\n",
        "    # Autism section\n",
        "    if y < 160:\n",
        "        c.showPage()\n",
        "        y = height - 40\n",
        "    y -= 8\n",
        "    c.setFont(\"Helvetica-Bold\", 13)\n",
        "    c.drawString(100, y, \"Autism Screening\")\n",
        "    y -= 16\n",
        "    c.setFont(\"Helvetica\", 12)\n",
        "    c.drawString(100, y, f\"Autism Score: {autism_score:.3f}\")\n",
        "    y -= 14\n",
        "    c.drawString(100, y, f\"Verdict: {autism_verdict}\")\n",
        "\n",
        "    # ADHD section\n",
        "    y -= 22\n",
        "    c.setFont(\"Helvetica-Bold\", 13)\n",
        "    c.drawString(100, y, \"ADHD Screening\")\n",
        "    y -= 16\n",
        "    c.setFont(\"Helvetica\", 12)\n",
        "    c.drawString(100, y, f\"ADHD Score: {adhd_score:.3f}\")\n",
        "    y -= 14\n",
        "    c.drawString(100, y, f\"Verdict: {adhd_verdict}\")\n",
        "\n",
        "    # Dyscalculia section (New)\n",
        "    y -= 22\n",
        "    c.setFont(\"Helvetica-Bold\", 13)\n",
        "    c.drawString(100, y, \"Dyscalculia Screening\")\n",
        "    y -= 16\n",
        "    c.setFont(\"Helvetica\", 12)\n",
        "    c.drawString(100, y, f\"Dyscalculia Score: {dyscalculia_score:.3f}\")\n",
        "    y -= 14\n",
        "    c.drawString(100, y, f\"Verdict: {dyscalculia_verdict}\")\n",
        "\n",
        "\n",
        "    # Footer / signature\n",
        "    y -= 40\n",
        "    if y < 80:\n",
        "        c.showPage()\n",
        "        y = height - 40\n",
        "    c.setFont(\"Helvetica-Bold\", 12)\n",
        "    c.drawString(100, y, \"Clinician Signature: ________________________\")\n",
        "    c.save()\n",
        "    print(f\"PDF report '{pdf_filename}' generated successfully.\")\n",
        "\n",
        "# ---- Read sentences file helper ----\n",
        "def read_sentences_from_file(filename):\n",
        "    try:\n",
        "        with open(filename, \"r\", encoding=\"utf-8\") as file:\n",
        "            sentences = [s.strip() for s in file.readlines() if s.strip()]\n",
        "        return sentences\n",
        "    except FileNotFoundError:\n",
        "        print(f\"File '{filename}' not found. Create a file named sentences.txt with sentences (one per line).\")\n",
        "        return []\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred while reading '{filename}': {e}\")\n",
        "        return []\n",
        "\n",
        "# ---- Main program ----\n",
        "def main():\n",
        "    try:\n",
        "        user_responses = []\n",
        "        dyslexia_scores = []\n",
        "\n",
        "        user_name = input(\"\\nPlease enter the patient's name: \").strip() or \"anonymous\"\n",
        "        user_id = input(\"Please enter the patient's ID: \").strip() or \"0000\"\n",
        "\n",
        "        # ---------- Dyslexia test (3 attempts) ----------\n",
        "        print(\"\\n=== Dyslexia sentence-copy test ===\")\n",
        "        max_attempts = 3\n",
        "        sentences = read_sentences_from_file(\"sentences.txt\")\n",
        "        if not sentences:\n",
        "            return\n",
        "\n",
        "        for attempt in range(max_attempts):\n",
        "            random_sentence = random.choice(sentences)\n",
        "            print(f\"\\nGenerated Sentence (Attempt {attempt + 1}): {random_sentence}\")\n",
        "            while True:\n",
        "                user_text = input(\"Enter the sentence for analysis: \\n\").strip()\n",
        "                if not user_text:\n",
        "                    print(\"Empty input. Try again.\")\n",
        "                    continue\n",
        "                if is_exact_match(user_text, random_sentence) or are_strings_similar(user_text, random_sentence, SIMILARITY_THRESHOLD):\n",
        "                    user_responses.append(user_text)\n",
        "                    score = dyslexia_analysis(user_text, random_sentence)\n",
        "                    dyslexia_scores.append(score)\n",
        "                    print(f\"Recorded. (score {score:.3f})\")\n",
        "                    break\n",
        "                else:\n",
        "                    print(\"Response is too different from the generated sentence. Please try again.\")\n",
        "                    time.sleep(0.5)\n",
        "                    print(f\"Copy this sentence: {random_sentence}\")\n",
        "\n",
        "        avg_dys_score = round(sum(dyslexia_scores) / len(dyslexia_scores), 3) if dyslexia_scores else 0.0\n",
        "        dyslexia_verdict = \"Likelihood of dyslexia detected.\" if avg_dys_score >= DYSLEXIA_SCORE_THRESHOLD else \"No significant signs of dyslexia detected.\"\n",
        "        print(f\"\\nAverage Dyslexia Score: {avg_dys_score:.3f} -> {dyslexia_verdict}\")\n",
        "\n",
        "        # ---------- Behavioral questionnaire ----------\n",
        "        print(\"\\n=== Short behavioral questionnaire (type one of: never, lessOften, sometimes, moreOften) ===\")\n",
        "        answers = {}\n",
        "\n",
        "        print(\"\\n-- Autism-related questions --\")\n",
        "        for key, prompt in AUTISM_QUESTIONS:\n",
        "            answer = ask_question(prompt)\n",
        "            answers[key] = answer\n",
        "\n",
        "        print(\"\\n-- ADHD-related questions --\")\n",
        "        for key, prompt in ADHD_QUESTIONS:\n",
        "            # reuse answers dict (some items overlap)\n",
        "            if key in answers:\n",
        "                # don't repeat; just show existing value\n",
        "                print(f\"{prompt} (answered above as '{answers[key]}')\")\n",
        "            else:\n",
        "                answer = ask_question(prompt)\n",
        "                answers[key] = answer\n",
        "\n",
        "        autism_score = autism_analysis_from_answers(answers)\n",
        "        adhd_score = adhd_analysis_from_answers(answers)\n",
        "\n",
        "        autism_verdict = \"High likelihood of autism-related traits.\" if autism_score >= AUTISM_THRESHOLD else \"Low / no significant autism-related traits detected.\"\n",
        "        adhd_verdict = \"High likelihood of ADHD-related traits.\" if adhd_score >= ADHD_THRESHOLD else \"Low / no significant ADHD-related traits detected.\"\n",
        "\n",
        "        print(f\"\\nAutism Score: {autism_score:.3f} -> {autism_verdict}\")\n",
        "        print(f\"ADHD Score: {adhd_score:.3f} -> {adhd_verdict}\")\n",
        "\n",
        "        # ---------- Generate PDF ----------\n",
        "        generate_pdf_report(user_responses, dyslexia_scores, avg_dys_score, dyslexia_verdict,\n",
        "                            autism_score, autism_verdict, adhd_score, adhd_verdict,\n",
        "                            user_name, user_id)\n",
        "\n",
        "    except KeyboardInterrupt:\n",
        "        print(\"\\nOperation aborted by the user.\")\n",
        "\n"
      ],
      "metadata": {
        "id": "ymc85FqClG1G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c90c3125",
        "outputId": "7ed7c05b-6a92-47f3-e6af-31010ede9099"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt_tab')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    }
  ]
}